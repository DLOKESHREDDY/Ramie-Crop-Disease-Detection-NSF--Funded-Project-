{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1512654,"sourceType":"datasetVersion","datasetId":891340}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom PIL import Image\nfrom sklearn.naive_bayes import GaussianNB\nimport shutil","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define function to load and preprocess images\ndef load_and_preprocess_images(image_paths):\n    # Initialize an empty list to store preprocessed images\n    preprocessed_images = []\n    for image_path in image_paths:\n        # Load image\n        image = Image.open(image_path)\n        # Preprocess image (resize, normalize, etc.)\n        # Example: resize image to (224, 224) and normalize pixel values to [0, 1]\n        image = image.resize((224, 224))  \n        image = np.array(image) / 255.0  # Normalize pixel values\n        # Append preprocessed image to the list\n        preprocessed_images.append(image)\n    # Convert list of images to a 4D array (num_samples, height, width, channels)\n    preprocessed_images = np.array(preprocessed_images)\n    # Reshape the array to 2D (num_samples, height * width * channels)\n    preprocessed_images = preprocessed_images.reshape(preprocessed_images.shape[0], -1)\n    return preprocessed_images","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_images(directory):\n    count = 0\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n                count += 1\n    return count\n#testing the number of images for testing\ntest_dir = '/kaggle/input/cotton-disease-dataset/Cotton Disease/test'\nnum_images = count_images(test_dir)\nprint(f'Total number of images in the test dataset: {num_images}')\n#testing the number of images for training\ntest_dir = '/kaggle/input/cotton-disease-dataset/Cotton Disease/train'\nnum_images = count_images(test_dir)\nprint(f'Total number of images in the training dataset: {num_images}')\n#testing the number of images for val\ntest_dir = '/kaggle/input/cotton-disease-dataset/Cotton Disease/val'\nnum_images = count_images(test_dir)\nprint(f'Total number of images in the val dataset: {num_images}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define function for local model training\ndef local_train(X_local, y_local):\n    clf = SVC(kernel='linear', probability=True, random_state=42)\n    clf.fit(X_local, y_local)\n    return clf\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define function for model evaluation\ndef evaluate_model(model, X_test, y_test):\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    y_pred_proba = model.predict_proba(X_test)\n    return accuracy, y_pred, y_pred_proba\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = \"/kaggle/input/cotton-disease-dataset/Cotton Disease\"\n# Define paths to the train, test, and val directories\ntrain_path = '/kaggle/input/cotton-disease-dataset/Cotton Disease/train'\ntest_path = '/kaggle/input/cotton-disease-dataset/Cotton Disease/test'\nval_path = '/kaggle/input/cotton-disease-dataset/Cotton Disease/val'\n# Define the path to the combined directory\ncombined_path = '/kaggle/working/combined_dataset'\n\n# Create the combined directory if it doesn't exist\nos.makedirs(combined_path, exist_ok=True)\n# Function to copy images from source directory to destination directory\ndef copy_images(source_dir, dest_dir):\n    for subdir in os.listdir(source_dir):\n        subdir_path = os.path.join(source_dir, subdir)\n        if os.path.isdir(subdir_path):\n            for file in os.listdir(subdir_path):\n                file_path = os.path.join(subdir_path, file)\n                if os.path.isfile(file_path):\n                    dest_subdir_path = os.path.join(dest_dir, subdir)\n                    os.makedirs(dest_subdir_path, exist_ok=True)\n                    try:\n                        shutil.copy(file_path, os.path.join(dest_subdir_path, file))\n                        print(f\"Successfully copied: {file_path}\")\n                    except Exception as e:\n                        print(f\"Error copying file: {file_path}, Error: {e}\")\n# Copy images from train directory\ncopy_images(train_path, combined_path)\n\n# Copy images from test directory\ncopy_images(test_path, combined_path)\n\n# Copy images from val directory\ncopy_images(val_path, combined_path)\n\nprint(\"Images combined successfully.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Directory containing the dataset\ndataset_dir = \"/kaggle/working/combined_dataset\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# List of classes (subdirectories) in the dataset directory\nclasses = os.listdir(dataset_dir)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combine all data from different classes\nX, y = [], []\nfor class_name in classes:\n    class_dir = os.path.join(dataset_dir, class_name)\n    image_files = os.listdir(class_dir)\n    for image_file in image_files:\n        image_path = os.path.join(class_dir, image_file)\n        X.append(image_path)\n        y.append(class_name)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert class labels to numeric labels\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load and preprocess images for the training set\nX_train_processed = load_and_preprocess_images(X_train)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the local model\nlocal_model = local_train(X_train_processed, y_train)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load and preprocess images for the testing set\nX_test_processed = load_and_preprocess_images(X_test)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define function for local model training using Naive Bayes\ndef local_train_nb(X_local, y_local):\n    clf = GaussianNB()\n    clf.fit(X_local, y_local)\n    return clf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the local model using Naive Bayes\nlocal_model_nb = local_train_nb(X_train_processed, y_train)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the local model using Naive Bayes\naccuracy_nb, y_pred_nb, y_pred_proba_nb = evaluate_model(local_model_nb, X_test_processed, y_test)\nprint(f\"Local Model Accuracy (Naive Bayes): {accuracy_nb * 100:.2f}%\")\n\n\n# Calculate ROC AUC score using predicted probabilities for Naive Bayes\nroc_auc_nb = roc_auc_score(y_test, y_pred_proba_nb, average='macro', multi_class='ovr')\nprint(\"ROC AUC Score (Naive Bayes):\", roc_auc_nb)\n\n# Generate classification report for Naive Bayes\nprint(\"Classification Report (Naive Bayes):\")\nprint(classification_report(y_test, y_pred_nb))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate confusion matrix for Naive Bayes\nprint(\"Confusion Matrix (Naive Bayes):\")\nprint(confusion_matrix(y_test, y_pred_nb))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot ROC curve for Naive Bayes\nn_classes = len(classes)\ny_test_binarized = label_binarize(y_test, classes=np.arange(n_classes))\nfpr_nb = dict()\ntpr_nb = dict()\nroc_auc_nb = dict()\nfor i in range(n_classes):\n    fpr_nb[i], tpr_nb[i], _ = roc_curve(y_test_binarized[:, i], y_pred_proba_nb[:, i])\n    roc_auc_nb[i] = auc(fpr_nb[i], tpr_nb[i])\n\nplt.figure()\ncolors = ['blue', 'red', 'green', 'yellow']  # Add more colors if needed\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr_nb[i], tpr_nb[i], color=color, lw=2, label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc_nb[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) - Naive Bayes')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Naive Bayes","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nfrom sklearn.naive_bayes import GaussianNB\nimport seaborn as sns  # For heatmap plotting\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track the progress\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode the labels as integers\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Flatten the image data for Naive Bayes\ndata_flattened = data.reshape((data.shape[0], -1))\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data_flattened, labels, test_size=0.30, random_state=42)\n\n# Build and train a Naive Bayes model\nnb_model = GaussianNB()\n\n# Train the model\nnb_model.fit(trainX, trainY)\n\n# Predictions\npredictions = nb_model.predict(testX)\n\n# Print classification report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Calculate accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n# ROC curve and AUC calculation\n# Get probabilities for ROC calculation\ny_prob = nb_model.predict_proba(testX)\n\n# Binarize the true labels for multi-class ROC\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Variables for ROC calculation\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\n# Calculate ROC for each class\nfor i in range(len(le.classes_)):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_prob[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(5, 5))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal line for random guessing\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom skimage.feature import hog\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.preprocessing import label_binarize\n\n# Function to load and preprocess images with HOG features\ndef load_and_preprocess_images_hog(image_paths):\n    hog_features = []\n    for image_path in image_paths:\n        image = Image.open(image_path).convert('L')  # Convert to grayscale\n        image = image.resize((128, 128))  # Resize image\n        image = np.array(image) / 255.0  # Normalize pixel values\n        # Extract HOG features\n        features, _ = hog(image, pixels_per_cell=(16, 16), cells_per_block=(2, 2), visualize=True)\n        hog_features.append(features)\n    return np.array(hog_features)\n\n# Load images and labels\ndef load_data(data_dir):\n    X, y = [], []\n    for class_name in os.listdir(data_dir):\n        class_dir = os.path.join(data_dir, class_name)\n        for image_file in os.listdir(class_dir):\n            image_path = os.path.join(class_dir, image_file)\n            X.append(image_path)\n            y.append(class_name)\n    return X, y\n\n# Define paths to the train and test directories\ntrain_path = '/kaggle/input/cotton-disease-dataset/Cotton Disease/train'\ntest_path = '/kaggle/input/cotton-disease-dataset/Cotton Disease/test'\n\n# Combine all data from different classes\nX_train_paths, y_train = load_data(train_path)\n\n# Encode labels to numeric values\nlabel_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(y_train)\n\n# Preprocess the training data\nX_train = load_and_preprocess_images_hog(X_train_paths)\n\n# Apply PCA for dimensionality reduction\npca = PCA(n_components=0.95)  # Keep 95% of variance\nX_train_pca = pca.fit_transform(X_train)\n\n# Initialize the Naive Bayes model\nnb_model = OneVsRestClassifier(GaussianNB())\n\n# Perform Stratified K-Fold Cross-Validation\ncv = StratifiedKFold(n_splits=5)  # 5-fold cross-validation\naccuracies = cross_val_score(nb_model, X_train_pca, y_train, cv=cv, scoring='accuracy')\n\n# Plot the Cross-Validation Accuracy Curve\nplt.figure()\nplt.plot(range(1, len(accuracies) + 1), accuracies, marker='o', color='b', label='Accuracy per fold')\nplt.xlabel('Fold')\nplt.ylabel('Accuracy')\nplt.title('Cross-Validation Accuracy Curve')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Print the accuracies and the mean accuracy\nfor i, acc in enumerate(accuracies):\n    print(f\"Fold {i+1} Accuracy: {acc * 100:.2f}%\")\n\nmean_accuracy = np.mean(accuracies)\nprint(f\"Mean Cross-Validation Accuracy: {mean_accuracy * 100:.2f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# KNN code","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom PIL import Image\nimport shutil\n\n# Define function to load and preprocess images\ndef load_and_preprocess_images(image_paths):\n    preprocessed_images = []\n    for image_path in image_paths:\n        # Load image\n        image = Image.open(image_path)\n        # Preprocess image (resize, normalize, etc.)\n        image = image.resize((224, 224))  \n        image = np.array(image) / 255.0  # Normalize pixel values\n        preprocessed_images.append(image)\n    preprocessed_images = np.array(preprocessed_images)\n    preprocessed_images = preprocessed_images.reshape(preprocessed_images.shape[0], -1)\n    return preprocessed_images\n\ndata = \"/kaggle/input/cotton-disease-dataset/Cotton Disease\"\n\n# Define paths to the train, test, and val directories\ntrain_path = '/kaggle/input/cotton-disease-dataset/Cotton Disease/train'\ntest_path = '/kaggle/input/cotton-disease-dataset/Cotton Disease/test'\nval_path = '/kaggle/input/cotton-disease-dataset/Cotton Disease/val'\n\n# Define the path to the combined directory\ncombined_path = '/kaggle/working/combined_dataset'\n\n# Create the combined directory if it doesn't exist\nos.makedirs(combined_path, exist_ok=True)\n\n# Function to copy images from source directory to destination directory\ndef copy_images(source_dir, dest_dir):\n    for subdir in os.listdir(source_dir):\n        subdir_path = os.path.join(source_dir, subdir)\n        if os.path.isdir(subdir_path):\n            for file in os.listdir(subdir_path):\n                file_path = os.path.join(subdir_path, file)\n                if os.path.isfile(file_path):\n                    dest_subdir_path = os.path.join(dest_dir, subdir)\n                    os.makedirs(dest_subdir_path, exist_ok=True)\n                    try:\n                        shutil.copy(file_path, os.path.join(dest_subdir_path, file))\n                        print(f\"Successfully copied: {file_path}\")\n                    except Exception as e:\n                        print(f\"Error copying file: {file_path}, Error: {e}\")\n\n# Copy images from train, test, and val directories\ncopy_images(train_path, combined_path)\ncopy_images(test_path, combined_path)\ncopy_images(val_path, combined_path)\n\nprint(\"Images combined successfully.\")\n\n# Directory containing the dataset\ndataset_dir = \"/kaggle/working/combined_dataset\"\n\n# List of classes (subdirectories) in the dataset directory\nclasses = os.listdir(dataset_dir)\n\n# Combine all data from different classes\nX, y = [], []\nfor class_name in classes:\n    class_dir = os.path.join(dataset_dir, class_name)\n    image_files = os.listdir(class_dir)\n    for image_file in image_files:\n        image_path = os.path.join(class_dir, image_file)\n        X.append(image_path)\n        y.append(class_name)\n\n# Convert class labels to numeric labels\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Load and preprocess images for the training set\nX_train_processed = load_and_preprocess_images(X_train)\n\n# Define function for local model training using KNN\ndef local_train_knn(X_local, y_local, n_neighbors=3):\n    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n    clf.fit(X_local, y_local)\n    return clf\n\n# Train the local model using KNN\nlocal_model_knn = local_train_knn(X_train_processed, y_train)\n\n# Load and preprocess images for the testing set\nX_test_processed = load_and_preprocess_images(X_test)\n\n# Define function to evaluate the model\ndef evaluate_model(model, X_test, y_test):\n    y_pred = model.predict(X_test)\n    y_pred_proba = model.predict_proba(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    return accuracy, y_pred, y_pred_proba\n\n# Evaluate the local model using KNN\naccuracy_knn, y_pred_knn, y_pred_proba_knn = evaluate_model(local_model_knn, X_test_processed, y_test)\nprint(f\"Local Model Accuracy (KNN): {accuracy_knn * 100:.2f}%\")\n\n# Calculate ROC AUC score using predicted probabilities for KNN\nroc_auc_knn = roc_auc_score(y_test, y_pred_proba_knn, average='macro', multi_class='ovr')\nprint(\"ROC AUC Score (KNN):\", roc_auc_knn)\n\n# Generate classification report for KNN\nprint(\"Classification Report (KNN):\")\nprint(classification_report(y_test, y_pred_knn))\n\n# Confusion Matrix\ncm = confusion_matrix(y_test, y_pred_knn)\nprint(\"Confusion Matrix (KNN):\\n\", cm)\n\n# # Plot Confusion Matrix\n# plt.figure(figsize=(8,6))\n# plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n# plt.title('Confusion Matrix (KNN)')\n# plt.colorbar()\n# tick_marks = np.arange(len(classes))\n# plt.xticks(tick_marks, classes, rotation=45)\n# plt.yticks(tick_marks, classes)\n# plt.tight_layout()\n# plt.ylabel('True label')\n# plt.xlabel('Predicted label')\n# plt.show()\n\n# Plot ROC Curve\nn_classes = len(classes)\ny_test_binarized = label_binarize(y_test, classes=[i for i in range(n_classes)])\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_pred_proba_knn[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot each class's ROC curve\nplt.figure()\nfor i in range(n_classes):\n    plt.plot(fpr[i], tpr[i], label=f'ROC curve of class {i} (area = {roc_auc[i]:.2f})')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve (KNN)')\nplt.legend(loc='lower right')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\nfrom sklearn.neighbors import KNeighborsClassifier\nimport seaborn as sns  # Import seaborn for heatmap plotting\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track the progress\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode the labels as integers\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Normalize image data (optional but improves performance)\ntrainX = trainX.astype('float32') / 255.0\ntestX = testX.astype('float32') / 255.0\n\n# Flatten the images for KNN\ntrainX_flat = trainX.reshape(trainX.shape[0], -1)  # Reshape to (num_samples, height * width * channels)\ntestX_flat = testX.reshape(testX.shape[0], -1)\n\n# Create a KNN classifier\nknn = KNeighborsClassifier(n_neighbors=5)  # You can adjust n_neighbors as needed\n\n# Train the KNN model\nknn.fit(trainX_flat, trainY)\n\n# Make predictions\npredictions = knn.predict(testX_flat)\n\n# Print classification report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Calculate accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n# ROC curve and AUC calculation\n# Binarize the output\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Variables for ROC calculation\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\n# Calculate ROC for each class\nfor i in range(len(le.classes_)):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], knn.predict_proba(testX_flat)[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(5, 5))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal line for random guessing\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CNN Code without Data Augmentation","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.utils import to_categorical\nimport seaborn as sns  # Make sure to import seaborn for heatmap plotting\n\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track the progress\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode the labels as integers\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Convert labels to categorical (one-hot encoding)\nlabels = to_categorical(labels)\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Normalize image data (optional but improves performance)\ntrainX = trainX.astype('float32') / 255.0\ntestX = testX.astype('float32') / 255.0\n\n# Build a CNN model\nmodel = Sequential()\n\n# Add convolutional, pooling, and fully connected layers\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\n\n# Add fully connected (dense) layers\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\n\n# Output layer (number of classes must match the number of labels)\nnum_classes = labels.shape[1]\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY))\n\n# Plot accuracy and loss curves\nplt.figure(figsize=(12, 5))\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy Curve')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss Curve')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Predictions\npredictions = model.predict(testX)\npredicted_labels = np.argmax(predictions, axis=1)\ntrue_labels = np.argmax(testY, axis=1)\n\n# Print classification report\nprint(classification_report(true_labels, predicted_labels, target_names=le.classes_))\n\n# Calculate accuracy\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(true_labels, predicted_labels)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n# ROC curve and AUC calculation\n# Get probabilities for ROC calculation\ny_bin = label_binarize(true_labels, classes=list(range(num_classes)))\n\n# Variables for ROC calculation\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\n# Calculate ROC for each class\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], predictions[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(5, 5))\n\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal line for random guessing\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**CNN code with data augmentation**# ","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport seaborn as sns  # Make sure to import seaborn for heatmap plotting\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track the progress\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode the labels as integers\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Convert labels to categorical (one-hot encoding)\nlabels = to_categorical(labels)\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Normalize image data (optional but improves performance)\ntrainX = trainX.astype('float32') / 255.0\ntestX = testX.astype('float32') / 255.0\n\n# Data Augmentation using ImageDataGenerator\ndatagen = ImageDataGenerator(\n    rotation_range=20,       # Randomly rotate images\n    width_shift_range=0.2,   # Randomly shift images horizontally\n    height_shift_range=0.2,  # Randomly shift images vertically\n    shear_range=0.15,        # Shear transformations\n    zoom_range=0.15,         # Zoom transformations\n    horizontal_flip=True,    # Flip images horizontally\n    fill_mode='nearest'      # Fill in new pixels with nearest neighbors\n)\n\n# Fit the generator to the training data\ndatagen.fit(trainX)\n\n# Build a CNN model\nmodel = Sequential()\n\n# Add convolutional, pooling, and fully connected layers\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\n\n# Add fully connected (dense) layers\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\n\n# Output layer (number of classes must match the number of labels)\nnum_classes = labels.shape[1]\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model using the augmented data\nhistory = model.fit(datagen.flow(trainX, trainY, batch_size=32), epochs=10, validation_data=(testX, testY))\n\n# Predictions\npredictions = model.predict(testX)\npredicted_labels = np.argmax(predictions, axis=1)\ntrue_labels = np.argmax(testY, axis=1)\n\n# Print classification report\nprint(classification_report(true_labels, predicted_labels, target_names=le.classes_))\n\n# Calculate accuracy\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(true_labels, predicted_labels)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n# Plotting Accuracy and Loss Curves\nplt.figure(figsize=(12, 4))\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Show the plots\nplt.tight_layout()\nplt.show()\n\n# ROC curve and AUC calculation\n# Get probabilities for ROC calculation\ny_bin = label_binarize(true_labels, classes=list(range(num_classes)))\n\n# Variables for ROC calculation\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\n# Calculate ROC for each class\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], predictions[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(5, 5))\n\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal line for random guessing\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CNN with VGG16 using DA , similarly not \n# power point of results - monday - done\n# include ROC curve with four classes - done\n# KNN using federated learning","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CNN with VGG16 without data augmentation","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.optimizers import Adam\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track the progress\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # VGG16 input size is 224x224\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode the labels as integers\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Convert labels to categorical (one-hot encoding)\nlabels = to_categorical(labels)\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Normalize image data (optional but improves performance)\ntrainX = trainX.astype('float32') / 255.0\ntestX = testX.astype('float32') / 255.0\n\n# Load the VGG16 model, excluding the top fully connected layers\nvgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freeze the base VGG16 layers to prevent them from being trained\nfor layer in vgg_base.layers:\n    layer.trainable = False\n\n# Build a new model on top of VGG16\nmodel = Sequential()\n\n# Add the VGG16 base model\nmodel.add(vgg_base)\n\n# Flatten the output from VGG16\nmodel.add(Flatten())\n\n# Add custom fully connected layers\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))  # Add dropout to reduce overfitting\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# Output layer (number of classes must match the number of labels)\nnum_classes = labels.shape[1]\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model without data augmentation\nhistory = model.fit(trainX, trainY, batch_size=32, epochs=10, validation_data=(testX, testY))\n\n# Predictions\npredictions = model.predict(testX)\npredicted_labels = np.argmax(predictions, axis=1)\ntrue_labels = np.argmax(testY, axis=1)\n\n# Print classification report\nprint(classification_report(true_labels, predicted_labels, target_names=le.classes_))\n\n# Calculate accuracy\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(true_labels, predicted_labels)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n# Plotting Accuracy and Loss Curves\nplt.figure(figsize=(12, 4))\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Show the plots\nplt.tight_layout()\nplt.show()\n\n# ROC curve and AUC calculation\n# Get probabilities for ROC calculation\ny_bin = label_binarize(true_labels, classes=list(range(num_classes)))\n\n# Variables for ROC calculation\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\n# Calculate ROC for each class\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], predictions[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(5, 5))\n\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal line for random guessing\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CNN using VGG16 with Data augmentation","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # VGG16 input size is 224x224\n    data.append(img)\n\n# Encode the labels as integers\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Convert labels to categorical (one-hot encoding)\nlabels = to_categorical(labels)\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Normalize image data (optional but improves performance)\ntrainX = trainX.astype('float32') / 255.0\ntestX = testX.astype('float32') / 255.0\n\n# Data Augmentation using ImageDataGenerator\ndatagen = ImageDataGenerator(\n    rotation_range=20,       # Randomly rotate images\n    width_shift_range=0.2,   # Randomly shift images horizontally\n    height_shift_range=0.2,  # Randomly shift images vertically\n    shear_range=0.15,        # Shear transformations\n    zoom_range=0.15,         # Zoom transformations\n    horizontal_flip=True,    # Flip images horizontally\n    fill_mode='nearest'      # Fill in new pixels with nearest neighbors\n)\n\n# Fit the generator to the training data\ndatagen.fit(trainX)\n\n# Load the VGG16 model, excluding the top fully connected layers\nvgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freeze the base VGG16 layers to prevent them from being trained\nfor layer in vgg_base.layers:\n    layer.trainable = False\n\n# Build a new model on top of VGG16\nmodel = Sequential()\n\n# Add the VGG16 base model\nmodel.add(vgg_base)\n\n# Flatten the output from VGG16\nmodel.add(Flatten())\n\n# Add custom fully connected layers\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))  # Add dropout to reduce overfitting\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# Output layer (number of classes must match the number of labels)\nnum_classes = labels.shape[1]\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model using the augmented data\nhistory = model.fit(datagen.flow(trainX, trainY, batch_size=32), epochs=10, validation_data=(testX, testY))\n\n# Predictions\npredictions = model.predict(testX)\npredicted_labels = np.argmax(predictions, axis=1)\ntrue_labels = np.argmax(testY, axis=1)\n\n# Print classification report\nprint(classification_report(true_labels, predicted_labels, target_names=le.classes_))\n\n# Calculate accuracy\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(true_labels, predicted_labels)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n# Plotting Accuracy and Loss Curves\nplt.figure(figsize=(12, 4))\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Show the plots\nplt.tight_layout()\nplt.show()\n\n# ROC curve and AUC calculation\n# Get probabilities for ROC calculation\ny_bin = label_binarize(true_labels, classes=list(range(num_classes)))\n\n# Variables for ROC calculation\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\n# Calculate ROC for each class\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], predictions[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(5, 5))\n\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal line for random guessing\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Update the word paper(discussion), Knn using federated learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_auc_score\n\n# Helper function to load images\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n    data.append(img)\n\n# Encode the labels as integers\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Normalize image data\ntrainX = trainX.astype('float32') / 255.0\ntestX = testX.astype('float32') / 255.0\n\n# PyTorch dataset definition\nclass ImageDataset(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# Data transformation (PyTorch's transforms for data augmentation)\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ToTensor()\n])\n\n# Create PyTorch Datasets and DataLoaders\ntrain_dataset = ImageDataset(trainX, trainY, transform=transform)\ntest_dataset = ImageDataset(testX, testY, transform=transforms.ToTensor())\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Partition the data to simulate clients in Federated Learning\ndef create_clients(data, labels, num_clients=5):\n    client_data = []\n    split_size = len(data) // num_clients\n    for i in range(num_clients):\n        client_data.append((data[i * split_size:(i + 1) * split_size], labels[i * split_size:(i + 1) * split_size]))\n    return client_data\n\n# Create 5 clients\nclients = create_clients(trainX, trainY, num_clients=5)\n\n# Federated Learning process with KNN on each client\ndef client_knn_train(client_data, n_neighbors=3):\n    # Unpack client data\n    X_train, y_train = client_data\n    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n    knn.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n    return knn\n\n# Train KNN model on each client and store the models\nclient_models = []\nfor client_data in clients:\n    model = client_knn_train(client_data)\n    client_models.append(model)\n\n# Aggregate predictions from clients\ndef federated_knn_predict(client_models, X_test):\n    # Reshape test data to fit KNN input\n    X_test = X_test.reshape(X_test.shape[0], -1)\n    predictions = []\n\n    # Each client predicts\n    for model in client_models:\n        preds = model.predict(X_test)\n        predictions.append(preds)\n    \n    # Aggregate predictions (e.g., majority vote)\n    predictions = np.array(predictions)\n    aggregated_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n    \n    return aggregated_predictions\n\n# Test the federated KNN model\npredicted_labels = federated_knn_predict(client_models, testX)\n\n# Calculate accuracy\naccuracy = accuracy_score(testY, predicted_labels)\nprint(f\"Federated KNN Accuracy: {accuracy * 100:.2f}%\")\n\n# Print classification report\nprint(classification_report(testY, predicted_labels, target_names=le.classes_))\n\n# Confusion matrix\nconf_matrix = confusion_matrix(testY, predicted_labels)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n# Binarize the labels for ROC calculation (one-vs-rest)\nn_classes = len(np.unique(testY))\ny_test_bin = label_binarize(testY, classes=[0, 1, 2, 3])  # Assume 4 classes, replace with your actual number of classes\ny_pred_bin = label_binarize(predicted_labels, classes=[0, 1, 2, 3])\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_bin[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot the ROC curves for all classes\nplt.figure()\ncolors = ['blue', 'red', 'green', 'orange']  # One color per class\n\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f'Class {i} (area = {roc_auc[i]:0.2f})')\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) for Multi-Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# Print ROC AUC score for overall model\nroc_auc_score_value = roc_auc_score(y_test_bin, y_pred_bin, average='macro')\nprint(f\"Overall ROC AUC Score: {roc_auc_score_value:.2f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# kNN Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\n\n# Helper function to load images\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n    data.append(img)\n\n# Encode the labels as integers\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Normalize image data\ntrainX = trainX.astype('float32') / 255.0\ntestX = testX.astype('float32') / 255.0\n\n# PyTorch dataset definition\nclass ImageDataset(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# Data transformation (PyTorch's transforms for data augmentation)\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ToTensor()\n])\n\n# Create PyTorch Datasets and DataLoaders\ntrain_dataset = ImageDataset(trainX, trainY, transform=transform)\ntest_dataset = ImageDataset(testX, testY, transform=transforms.ToTensor())\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Partition the data to simulate clients in Federated Learning\ndef create_clients(data, labels, num_clients=5):\n    client_data = []\n    split_size = len(data) // num_clients\n    for i in range(num_clients):\n        client_data.append((data[i * split_size:(i + 1) * split_size], labels[i * split_size:(i + 1) * split_size]))\n    return client_data\n\n# Create 5 clients\nclients = create_clients(trainX, trainY, num_clients=5)\n\n# Federated Learning process with KNN on each client\ndef client_knn_train(client_data, n_neighbors=3):\n    # Unpack client data\n    X_train, y_train = client_data\n    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n    knn.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n    return knn\n\n# Train KNN model on each client and store the models\nclient_models = []\nfor client_data in clients:\n    model = client_knn_train(client_data)\n    client_models.append(model)\n\n# Aggregate predictions from clients\ndef federated_knn_predict(client_models, X_test):\n    X_test = X_test.reshape(X_test.shape[0], -1)\n    predictions = []\n    probabilities = []\n\n    for model in client_models:\n        preds = model.predict(X_test)\n        preds_proba = model.predict_proba(X_test)  # Get probabilities\n        predictions.append(preds)\n        probabilities.append(preds_proba)\n\n    predictions = np.array(predictions)\n    probabilities = np.array(probabilities)\n    aggregated_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n    \n    return aggregated_predictions, probabilities.mean(axis=0)  # Average probabilities\n\n# Test the federated KNN model\npredicted_labels, predicted_probs = federated_knn_predict(client_models, testX)\n\n# Calculate accuracy\naccuracy = accuracy_score(testY, predicted_labels)\nprint(f\"Federated KNN Accuracy: {accuracy * 100:.2f}%\")\n\n# Print classification report\nprint(classification_report(testY, predicted_labels, target_names=le.classes_))\n\n# Confusion matrix\nconf_matrix = confusion_matrix(testY, predicted_labels)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n# Calculate the ROC curve and AUC for each class\nn_classes = len(le.classes_)\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(testY == i, predicted_probs[:, i])  # Binary classification for class i\n    roc_auc[i] = auc(fpr[i], tpr[i])  # Area under the curve\n\n# Plot the ROC curves\nplt.figure()\nfor i in range(n_classes):\n    plt.plot(fpr[i], tpr[i], label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {le.classes_[i]}')\n    \nplt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc='lower right')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Random Forest Using Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\n\n# Helper function to load images\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n    data.append(img)\n\n# Encode the labels as integers\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Normalize image data\ntrainX = trainX.astype('float32') / 255.0\ntestX = testX.astype('float32') / 255.0\n\n# PyTorch dataset definition\nclass ImageDataset(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# Data transformation (PyTorch's transforms for data augmentation)\ntransform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ToTensor()\n])\n\n# Create PyTorch Datasets and DataLoaders\ntrain_dataset = ImageDataset(trainX, trainY, transform=transform)\ntest_dataset = ImageDataset(testX, testY, transform=transforms.ToTensor())\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Partition the data to simulate clients in Federated Learning\ndef create_clients(data, labels, num_clients=5):\n    client_data = []\n    split_size = len(data) // num_clients\n    for i in range(num_clients):\n        client_data.append((data[i * split_size:(i + 1) * split_size], labels[i * split_size:(i + 1) * split_size]))\n    return client_data\n\n# Create 5 clients\nclients = create_clients(trainX, trainY, num_clients=5)\n\n# Federated Learning process with Random Forest on each client\ndef client_rf_train(client_data, n_estimators=100):\n    # Unpack client data\n    X_train, y_train = client_data\n    rf = RandomForestClassifier(n_estimators=n_estimators)\n    rf.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n    return rf\n\n# Train Random Forest model on each client and store the models\nclient_models = []\nfor client_data in clients:\n    model = client_rf_train(client_data)\n    client_models.append(model)\n\n# Aggregate predictions from clients\ndef federated_rf_predict(client_models, X_test):\n    X_test = X_test.reshape(X_test.shape[0], -1)\n    predictions = []\n\n    for model in client_models:\n        preds = model.predict(X_test)\n        predictions.append(preds)\n\n    # Aggregate predictions by majority voting\n    predictions = np.array(predictions)\n    aggregated_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n    \n    return aggregated_predictions\n\n# Test the federated Random Forest model\npredicted_labels = federated_rf_predict(client_models, testX)\n\n# Calculate accuracy\naccuracy = accuracy_score(testY, predicted_labels)\nprint(f\"Federated Random Forest Accuracy: {accuracy * 100:.2f}%\")\n\n# Print classification report\nprint(classification_report(testY, predicted_labels, target_names=le.classes_))\n\n# Confusion matrix\nconf_matrix = confusion_matrix(testY, predicted_labels)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n# Calculate the ROC curve and AUC for each class\nn_classes = len(le.classes_)\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\n# For Random Forest, we can get the probabilities for ROC calculation\ndef federated_rf_predict_proba(client_models, X_test):\n    X_test = X_test.reshape(X_test.shape[0], -1)\n    probabilities = []\n\n    for model in client_models:\n        probs = model.predict_proba(X_test)\n        probabilities.append(probs)\n\n    probabilities = np.array(probabilities)\n    return probabilities.mean(axis=0)  # Average probabilities\n\npredicted_probs = federated_rf_predict_proba(client_models, testX)\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(testY == i, predicted_probs[:, i])  # Binary classification for class i\n    roc_auc[i] = auc(fpr[i], tpr[i])  # Area under the curve\n\n# Plot the ROC curves\nplt.figure()\nfor i in range(n_classes):\n    plt.plot(fpr[i], tpr[i], label=f'ROC curve (area = {roc_auc[i]:.2f}) for class {le.classes_[i]}')\n    \nplt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc='lower right')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"work on MobileNet, ResNet, Update the word doc without fedearted learning, **Random Forest, SVM (without federated learning).**","metadata":{}},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nimport seaborn as sns  # Make sure to import seaborn for heatmap plotting\n\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track the progress\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode the labels as integers\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Flatten the image data for Random Forest\ndata_flattened = data.reshape((data.shape[0], -1))\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data_flattened, labels, test_size=0.30, random_state=42)\n\n# Build and train a Random Forest model\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nrf_model.fit(trainX, trainY)\n\n# Predictions\npredictions = rf_model.predict(testX)\n\n# Print classification report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Calculate accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n# ROC curve and AUC calculation\n# Get probabilities for ROC calculation\ny_prob = rf_model.predict_proba(testX)\n\n# Binarize the true labels for multi-class ROC\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Variables for ROC calculation\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\n# Calculate ROC for each class\nfor i in range(len(le.classes_)):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_prob[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(5, 5))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal line for random guessing\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SVM","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nfrom sklearn.svm import SVC\nfrom sklearn import metrics\nimport seaborn as sns  # Make sure to import seaborn for heatmap plotting\n\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track the progress\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode the labels as integers\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Flatten the image data for SVM\ndata_flattened = data.reshape((data.shape[0], -1))\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data_flattened, labels, test_size=0.30, random_state=42)\n\n# Normalize image data for SVM (scaling improves performance)\ntrainX = trainX.astype('float32') / 255.0\ntestX = testX.astype('float32') / 255.0\n\n# Build and train an SVM model\nsvm_model = SVC(kernel='linear', probability=True, random_state=42)\n\n# Train the model\nsvm_model.fit(trainX, trainY)\n\n# Predictions\npredictions = svm_model.predict(testX)\n\n# Print classification report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Calculate accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n# ROC curve and AUC calculation\n# Get probabilities for ROC calculation\ny_prob = svm_model.predict_proba(testX)\n\n# Binarize the true labels for multi-class ROC\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Variables for ROC calculation\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\n# Calculate ROC for each class\nfor i in range(len(le.classes_)):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_prob[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(5, 5))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal line for random guessing\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-04T19:29:06.350Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MobileNet without Data Augmentation","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.utils import to_categorical\nimport seaborn as sns\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track the progress\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # Resize to 224x224 for MobileNet\n    img = img_to_array(img)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode the labels as integers\ndata = np.array(data, dtype=\"float32\") / 255.0  # Normalize the data\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Convert labels to categorical (one-hot encoding)\nlabels = to_categorical(labels)\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Load the MobileNetV2 model, excluding the top layer (to add our custom layers)\nbase_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers on top of MobileNetV2\nx = base_model.output\nx = GlobalAveragePooling2D()(x)  # Global average pooling to reduce the dimensionality\nx = Dense(256, activation='relu')(x)  # Add fully connected layer\nx = Dense(128, activation='relu')(x)  # Another fully connected layer\n\n# Output layer (softmax for multi-class classification)\nnum_classes = labels.shape[1]\npredictions = Dense(num_classes, activation='softmax')(x)\n\n# Combine the base model with the new layers\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze the layers in the base model to avoid retraining them\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY))\n\n# Plot accuracy and loss curves\nplt.figure(figsize=(12, 5))\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy Curve')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss Curve')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Predictions\npredictions = model.predict(testX)\npredicted_labels = np.argmax(predictions, axis=1)\ntrue_labels = np.argmax(testY, axis=1)\n\n# Print classification report\nprint(classification_report(true_labels, predicted_labels, target_names=le.classes_))\n\n# Calculate accuracy\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(true_labels, predicted_labels)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n\n# ROC curve and AUC calculation\n# Binarize the true labels for multi-class ROC\ny_bin = label_binarize(true_labels, classes=list(range(num_classes)))\n\n# Variables for ROC calculation\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\n# Calculate ROC for each class\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], predictions[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(5, 5))\n\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal line for random guessing\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MobileNet with Data Augmentation","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport seaborn as sns\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track the progress\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # Resize to 224x224 for MobileNet\n    img = img_to_array(img)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode the labels as integers\ndata = np.array(data, dtype=\"float32\") / 255.0  # Normalize the data\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Convert labels to categorical (one-hot encoding)\nlabels = to_categorical(labels)\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Create an instance of ImageDataGenerator for data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=40,       # Random rotation\n    width_shift_range=0.2,   # Random horizontal shift\n    height_shift_range=0.2,  # Random vertical shift\n    shear_range=0.2,        # Random shear\n    zoom_range=0.2,         # Random zoom\n    horizontal_flip=True,    # Random horizontal flip\n    fill_mode='nearest'      # Fill in new pixels\n)\n\n# Fit the generator to the training data\ndatagen.fit(trainX)\n\n# Load the MobileNetV2 model, excluding the top layer (to add our custom layers)\nbase_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers on top of MobileNetV2\nx = base_model.output\nx = GlobalAveragePooling2D()(x)  # Global average pooling to reduce the dimensionality\nx = Dense(256, activation='relu')(x)  # Add fully connected layer\nx = Dense(128, activation='relu')(x)  # Another fully connected layer\n\n# Output layer (softmax for multi-class classification)\nnum_classes = labels.shape[1]\npredictions = Dense(num_classes, activation='softmax')(x)\n\n# Combine the base model with the new layers\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze the layers in the base model to avoid retraining them\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model using the data generator\nhistory = model.fit(datagen.flow(trainX, trainY, batch_size=32),\n                    epochs=10,\n                    validation_data=(testX, testY),\n                    steps_per_epoch=len(trainX) // 32)\n\n# Plot accuracy and loss curves\nplt.figure(figsize=(12, 5))\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy Curve')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss Curve')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Predictions\npredictions = model.predict(testX)\npredicted_labels = np.argmax(predictions, axis=1)\ntrue_labels = np.argmax(testY, axis=1)\n\n# Print classification report\nprint(classification_report(true_labels, predicted_labels, target_names=le.classes_))\n\n# Calculate accuracy\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(true_labels, predicted_labels)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n# ROC curve and AUC calculation\n# Binarize the true labels for multi-class ROC\ny_bin = label_binarize(true_labels, classes=list(range(num_classes)))\n\n# Variables for ROC calculation\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\n# Calculate ROC for each class\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], predictions[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(5, 5))\n\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal line for random guessing\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ResNet50 without Data Augmentation","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.utils import to_categorical\nimport seaborn as sns\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track the progress\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # Resize to 224x224 for ResNet\n    img = img_to_array(img)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode the labels as integers\ndata = np.array(data, dtype=\"float32\") / 255.0  # Normalize the data\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Convert labels to categorical (one-hot encoding)\nlabels = to_categorical(labels)\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Load the ResNet50 model, excluding the top layer (to add our custom layers)\nbase_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers on top of ResNet50\nx = base_model.output\nx = GlobalAveragePooling2D()(x)  # Global average pooling to reduce the dimensionality\nx = Dense(256, activation='relu')(x)  # Add fully connected layer\nx = Dense(128, activation='relu')(x)  # Another fully connected layer\n\n# Output layer (softmax for multi-class classification)\nnum_classes = labels.shape[1]\npredictions = Dense(num_classes, activation='softmax')(x)\n\n# Combine the base model with the new layers\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze the layers in the base model to avoid retraining them\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY))\n\n# Plot accuracy and loss curves\nplt.figure(figsize=(12, 5))\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy Curve')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss Curve')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Predictions\npredictions = model.predict(testX)\npredicted_labels = np.argmax(predictions, axis=1)\ntrue_labels = np.argmax(testY, axis=1)\n\n# Print classification report\nprint(classification_report(true_labels, predicted_labels, target_names=le.classes_))\n\n# Calculate accuracy\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(true_labels, predicted_labels)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n# ROC curve and AUC calculation\n# Binarize the true labels for multi-class ROC\ny_bin = label_binarize(true_labels, classes=list(range(num_classes)))\n\n# Variables for ROC calculation\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\n# Calculate ROC for each class\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], predictions[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(5, 5))\n\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal line for random guessing\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T19:30:57.058332Z","iopub.execute_input":"2025-02-28T19:30:57.058666Z","iopub.status.idle":"2025-02-28T19:33:40.347952Z","shell.execute_reply.started":"2025-02-28T19:30:57.058634Z","shell.execute_reply":"2025-02-28T19:33:40.347060Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Update the doc file results& discussion, Code: CNN - {MobileNet, ResNet50} -(with data Augmentation)","metadata":{}},{"cell_type":"markdown","source":"# ResNet50 With Data Augmentation","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nimport seaborn as sns\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track the progress\n\n# Loop through each image, load it, and preprocess it\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # Resize to 224x224 for ResNet\n    img = img_to_array(img)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode the labels as integers\ndata = np.array(data, dtype=\"float32\") / 255.0  # Normalize the data\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Convert labels to categorical (one-hot encoding)\nlabels = to_categorical(labels)\n\n# Split dataset into 70% training and 30% testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Create an instance of ImageDataGenerator for data augmentation\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Fit the generator on the training data\ntrain_datagen.fit(trainX)\n\n# Load the ResNet50 model, excluding the top layer (to add our custom layers)\nbase_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers on top of ResNet50\nx = base_model.output\nx = GlobalAveragePooling2D()(x)  # Global average pooling to reduce the dimensionality\nx = Dense(256, activation='relu')(x)  # Add fully connected layer\nx = Dense(128, activation='relu')(x)  # Another fully connected layer\n\n# Output layer (softmax for multi-class classification)\nnum_classes = labels.shape[1]\npredictions = Dense(num_classes, activation='softmax')(x)\n\n# Combine the base model with the new layers\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze the layers in the base model to avoid retraining them\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model using the augmented data\nhistory = model.fit(train_datagen.flow(trainX, trainY, batch_size=32),\n                    epochs=10,\n                    validation_data=(testX, testY))\n\n# Plot accuracy and loss curves\nplt.figure(figsize=(12, 5))\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy Curve')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss Curve')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Predictions\npredictions = model.predict(testX)\npredicted_labels = np.argmax(predictions, axis=1)\ntrue_labels = np.argmax(testY, axis=1)\n\n# Print classification report\nprint(classification_report(true_labels, predicted_labels, target_names=le.classes_))\n\n# Calculate accuracy\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion matrix\nconf_matrix = confusion_matrix(true_labels, predicted_labels)\nprint(\"Confusion matrix is:\")\nprint(conf_matrix)\n\n# ROC curve and AUC calculation\n# Binarize the true labels for multi-class ROC\ny_bin = label_binarize(true_labels, classes=list(range(num_classes)))\n\n# Variables for ROC calculation\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\n# Calculate ROC for each class\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], predictions[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(5, 5))\n\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal line for random guessing\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# FEDERATED LEARNING","metadata":{}},{"cell_type":"code","source":"pip install --upgrade opencv-python\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T01:14:20.778156Z","iopub.execute_input":"2025-01-23T01:14:20.778517Z","iopub.status.idle":"2025-01-23T01:14:32.813477Z","shell.execute_reply.started":"2025-01-23T01:14:20.778485Z","shell.execute_reply":"2025-01-23T01:14:32.812367Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Naive Bayes -  Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nfrom sklearn.naive_bayes import GaussianNB\nimport seaborn as sns  # For heatmap visualization\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Flatten images for Nave Bayes\ndata_flattened = data.reshape((data.shape[0], -1))\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data_flattened, labels, test_size=0.30, random_state=42)\n\n# Normalize image data (scaling improves performance)\ntrainX = trainX.astype('float32') / 255.0\ntestX = testX.astype('float32') / 255.0\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Train local models (Nave Bayes) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = GaussianNB()\n    model.fit(client_data[i], client_labels[i])\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Federated Aggregation: Combine client models into a global model\nglobal_model = GaussianNB()\n\n# Compute average probabilities from all client models\ndef aggregate_models(client_models, testX):\n    client_probs = [model.predict_proba(testX) for model in client_models]\n    avg_probs = np.mean(client_probs, axis=0)  # Averaging predicted probabilities\n    return np.argmax(avg_probs, axis=1), avg_probs\n\n# Get predictions from federated model\npredictions, y_prob = aggregate_models(client_models, testX)\n\n# Classification Report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Federated Nave Bayes Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_prob[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n\n\n# Troubleshooting, Time takes to run, Code to show the time it took.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T22:18:53.691051Z","iopub.execute_input":"2025-01-23T22:18:53.691836Z","iopub.status.idle":"2025-01-23T22:19:16.941856Z","shell.execute_reply.started":"2025-01-23T22:18:53.691799Z","shell.execute_reply":"2025-01-23T22:19:16.940833Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# KNN - Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\nimport seaborn as sns  # For heatmap visualization\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Flatten images for KNN\ndata_flattened = data.reshape((data.shape[0], -1))\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data_flattened, labels, test_size=0.30, random_state=42)\n\n# Normalize image data (scaling improves performance)\ntrainX = trainX.astype('float32') / 255.0\ntestX = testX.astype('float32') / 255.0\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Train local models (KNN) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = KNeighborsClassifier(n_neighbors=5)\n    model.fit(client_data[i], client_labels[i])\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Federated Aggregation: Combine client models into a global model\ndef aggregate_models(client_models, testX):\n    client_probs = [model.predict_proba(testX) for model in client_models]\n    avg_probs = np.mean(client_probs, axis=0)  # Averaging predicted probabilities\n    return np.argmax(avg_probs, axis=1), avg_probs\n\n# Get predictions from federated model\npredictions, y_prob = aggregate_models(client_models, testX)\n\n# Classification Report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Federated KNN Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_prob[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T22:23:09.684551Z","iopub.execute_input":"2025-01-23T22:23:09.684901Z","iopub.status.idle":"2025-01-23T22:23:31.470956Z","shell.execute_reply.started":"2025-01-23T22:23:09.684873Z","shell.execute_reply":"2025-01-23T22:23:31.469756Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Random Forest - Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nimport seaborn as sns  # For heatmap visualization\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Flatten images for Random Forest\ndata_flattened = data.reshape((data.shape[0], -1))\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data_flattened, labels, test_size=0.30, random_state=42)\n\n# Normalize image data (scaling improves performance)\ntrainX = trainX.astype('float32') / 255.0\ntestX = testX.astype('float32') / 255.0\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Train local models (Random Forest) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(client_data[i], client_labels[i])\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Federated Aggregation: Combine client models into a global model\nglobal_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Compute average probabilities from all client models\ndef aggregate_models(client_models, testX):\n    client_probs = [model.predict_proba(testX) for model in client_models]\n    avg_probs = np.mean(client_probs, axis=0)  # Averaging predicted probabilities\n    return np.argmax(avg_probs, axis=1), avg_probs\n\n# Get predictions from federated model\npredictions, y_prob = aggregate_models(client_models, testX)\n\n# Classification Report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Federated Random Forest Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_prob[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T22:25:05.652251Z","iopub.execute_input":"2025-01-23T22:25:05.652502Z","iopub.status.idle":"2025-01-23T22:25:37.054071Z","shell.execute_reply.started":"2025-01-23T22:25:05.652481Z","shell.execute_reply":"2025-01-23T22:25:37.053334Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SVM - Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nfrom sklearn.svm import SVC\nimport seaborn as sns  # For heatmap visualization\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Flatten images for SVM\ndata_flattened = data.reshape((data.shape[0], -1))\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data_flattened, labels, test_size=0.30, random_state=42)\n\n# Normalize image data (scaling improves performance)\ntrainX = trainX.astype('float32') / 255.0\ntestX = testX.astype('float32') / 255.0\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Train local models (SVM) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = SVC(kernel='linear', probability=True, random_state=42)\n    model.fit(client_data[i], client_labels[i])\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Federated Aggregation: Combine client models into a global model\nglobal_model = SVC(kernel='linear', probability=True, random_state=42)\n\n# Compute average probabilities from all client models\ndef aggregate_models(client_models, testX):\n    client_probs = [model.predict_proba(testX) for model in client_models]\n    avg_probs = np.mean(client_probs, axis=0)  # Averaging predicted probabilities\n    return np.argmax(avg_probs, axis=1), avg_probs\n\n# Get predictions from federated model\npredictions, y_prob = aggregate_models(client_models, testX)\n\n# Classification Report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Federated SVM Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_prob[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T22:27:19.128086Z","iopub.execute_input":"2025-01-23T22:27:19.128399Z","iopub.status.idle":"2025-01-23T22:27:46.528868Z","shell.execute_reply.started":"2025-01-23T22:27:19.128376Z","shell.execute_reply":"2025-01-23T22:27:46.527958Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CNN without Data Augmentation - Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport seaborn as sns  # For heatmap visualization\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Normalize image data (scaling improves performance)\ndata = data.astype('float32') / 255.0\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Handle class imbalance by computing class weights\nclass_weights = compute_class_weight('balanced', classes=np.unique(trainY), y=trainY)\nclass_weights_dict = dict(zip(np.unique(trainY), class_weights))\n\n# Define the CNN model\ndef create_cnn_model():\n    model = models.Sequential()\n    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(128, activation='relu'))\n    model.add(layers.Dense(len(le.classes_), activation='softmax'))  # For multi-class classification\n    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Train local models (CNN) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = create_cnn_model()\n    model.fit(client_data[i], client_labels[i], epochs=10, batch_size=32, class_weight=class_weights_dict, verbose=1)\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Federated Aggregation: Combine client models into a global model\ndef aggregate_models(client_models, testX):\n    client_preds = [model.predict(testX) for model in client_models]\n    avg_preds = np.mean(client_preds, axis=0)  # Averaging predicted probabilities\n    return np.argmax(avg_preds, axis=1)\n\n# Get predictions from federated model\npredictions = aggregate_models(client_models, testX)\n\n# Classification Report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Federated CNN Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    # Get class probabilities from each client model\n    probs = np.mean([model.predict(testX)[:, i] for model in client_models], axis=0)\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], probs)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T22:07:50.325981Z","iopub.execute_input":"2025-02-27T22:07:50.326344Z","iopub.status.idle":"2025-02-27T22:08:21.294533Z","shell.execute_reply.started":"2025-02-27T22:07:50.326313Z","shell.execute_reply":"2025-02-27T22:08:21.293583Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CNN with Data Augmentation - Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport seaborn as sns  # For heatmap visualization\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Normalize image data (scaling improves performance)\ndata = data.astype('float32') / 255.0\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Handle class imbalance by computing class weights\nclass_weights = compute_class_weight('balanced', classes=np.unique(trainY), y=trainY)\nclass_weights_dict = dict(zip(np.unique(trainY), class_weights))\n\n# Create ImageDataGenerator for data augmentation\ntrain_datagen = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Define the CNN model\ndef create_cnn_model():\n    model = models.Sequential()\n    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(128, activation='relu'))\n    model.add(layers.Dense(len(le.classes_), activation='softmax'))  # For multi-class classification\n    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Train local models (CNN) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = create_cnn_model()\n    model.fit(train_datagen.flow(client_data[i], client_labels[i], batch_size=32), \n              epochs=10, \n              class_weight=class_weights_dict, \n              verbose=1)\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Federated Aggregation: Combine client models into a global model\ndef aggregate_models(client_models, testX):\n    client_preds = [model.predict(testX) for model in client_models]\n    avg_preds = np.mean(client_preds, axis=0)  # Averaging predicted probabilities\n    return np.argmax(avg_preds, axis=1)\n\n# Get predictions from federated model\npredictions = aggregate_models(client_models, testX)\n\n# Classification Report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Federated CNN Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    # Get class probabilities from each client model\n    probs = np.mean([model.predict(testX)[:, i] for model in client_models], axis=0)\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], probs)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T22:10:52.366234Z","iopub.execute_input":"2025-02-27T22:10:52.366867Z","iopub.status.idle":"2025-02-27T22:11:33.881843Z","shell.execute_reply.started":"2025-02-27T22:10:52.366838Z","shell.execute_reply":"2025-02-27T22:11:33.880961Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CNN Via VGG16 with Data Augmentation - Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport seaborn as sns  # For heatmap visualization\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.optimizers import Adam\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # VGG16 input size\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Normalize image data (scaling improves performance)\ndata = data.astype('float32') / 255.0\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Handle class imbalance by computing class weights\nclass_weights = compute_class_weight('balanced', classes=np.unique(trainY), y=trainY)\nclass_weights_dict = dict(zip(np.unique(trainY), class_weights))\n\n# Create ImageDataGenerator for data augmentation\ntrain_datagen = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\ndef create_vgg16_cnn_model():\n    # Load VGG16 as a base model without the top layers\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    base_model.trainable = False  # Freeze the pre-trained layers\n\n    # Create custom CNN layers on top of VGG16\n    model = models.Sequential([\n        base_model,\n        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n        # Removed unnecessary pooling layer to avoid dimension issue\n        layers.GlobalAveragePooling2D(),  # Global Average Pooling to handle small feature maps\n        layers.Dense(128, activation='relu'),\n        layers.Dense(len(le.classes_), activation='softmax')  # For multi-class classification\n    ])\n    \n    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Train local models (CNN with VGG16 backbone) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = create_vgg16_cnn_model()\n    model.fit(train_datagen.flow(client_data[i], client_labels[i], batch_size=32), \n              epochs=10, \n              class_weight=class_weights_dict, \n              verbose=1)\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Federated Aggregation: Combine client models into a global model\ndef aggregate_models(client_models, testX):\n    client_preds = [model.predict(testX) for model in client_models]\n    avg_preds = np.mean(client_preds, axis=0)  # Averaging predicted probabilities\n    return np.argmax(avg_preds, axis=1)\n\n# Get predictions from federated model\npredictions = aggregate_models(client_models, testX)\n\n# Classification Report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Federated CNN with VGG16 Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    # Get class probabilities from each client model\n    probs = np.mean([model.predict(testX)[:, i] for model in client_models], axis=0)\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], probs)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T22:27:56.891929Z","iopub.execute_input":"2025-02-27T22:27:56.892260Z","iopub.status.idle":"2025-02-27T22:32:52.784050Z","shell.execute_reply.started":"2025-02-27T22:27:56.892236Z","shell.execute_reply":"2025-02-27T22:32:52.783228Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CNN Via VGG16 without Data Augementation - Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport seaborn as sns  # For heatmap visualization\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # VGG16 input size\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Normalize image data (scaling improves performance)\ndata = data.astype('float32') / 255.0\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Handle class imbalance by computing class weights\nclass_weights = compute_class_weight('balanced', classes=np.unique(trainY), y=trainY)\nclass_weights_dict = dict(zip(np.unique(trainY), class_weights))\n\n# Remove ImageDataGenerator (no augmentation now)\n# Create the model function\ndef create_vgg16_cnn_model():\n    # Load VGG16 as a base model without the top layers\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    base_model.trainable = False  # Freeze the pre-trained layers\n\n    # Create custom CNN layers on top of VGG16\n    model = models.Sequential([\n        base_model,\n        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n        # Removed unnecessary pooling layer to avoid dimension issue\n        layers.GlobalAveragePooling2D(),  # Global Average Pooling to handle small feature maps\n        layers.Dense(128, activation='relu'),\n        layers.Dense(len(le.classes_), activation='softmax')  # For multi-class classification\n    ])\n    \n    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Train local models (CNN with VGG16 backbone) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = create_vgg16_cnn_model()\n    model.fit(client_data[i], client_labels[i], batch_size=32, \n              epochs=10, \n              class_weight=class_weights_dict, \n              verbose=1)\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Federated Aggregation: Combine client models into a global model\ndef aggregate_models(client_models, testX):\n    client_preds = [model.predict(testX) for model in client_models]\n    avg_preds = np.mean(client_preds, axis=0)  # Averaging predicted probabilities\n    return np.argmax(avg_preds, axis=1)\n\n# Get predictions from federated model\npredictions = aggregate_models(client_models, testX)\n\n# Classification Report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Federated CNN with VGG16 Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    # Get class probabilities from each client model\n    probs = np.mean([model.predict(testX)[:, i] for model in client_models], axis=0)\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], probs)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T22:39:08.438531Z","iopub.execute_input":"2025-02-27T22:39:08.438943Z","iopub.status.idle":"2025-02-27T22:43:01.878422Z","shell.execute_reply.started":"2025-02-27T22:39:08.438915Z","shell.execute_reply":"2025-02-27T22:43:01.877475Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MobileNet with Data Augmentation - Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport seaborn as sns  # For heatmap visualization\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNet\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # MobileNet input size\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Normalize image data (scaling improves performance)\ndata = data.astype('float32') / 255.0\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Handle class imbalance by computing class weights\nclass_weights = compute_class_weight('balanced', classes=np.unique(trainY), y=trainY)\nclass_weights_dict = dict(zip(np.unique(trainY), class_weights))\n\n# Create ImageDataGenerator for data augmentation\ntrain_datagen = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Create the model function using MobileNet\ndef create_mobilenet_model():\n    # Load MobileNet as a base model without the top layers\n    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    base_model.trainable = False  # Freeze the pre-trained layers\n\n    # Use MobileNet with global average pooling and a dense classification layer\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),  # Global Average Pooling to handle small feature maps\n        layers.Dense(128, activation='relu'),\n        layers.Dense(len(le.classes_), activation='softmax')  # For multi-class classification\n    ])\n    \n    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Train local models (MobileNet backbone) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = create_mobilenet_model()\n    model.fit(train_datagen.flow(client_data[i], client_labels[i], batch_size=32), \n              epochs=10, \n              class_weight=class_weights_dict, \n              verbose=1)\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Federated Aggregation: Combine client models into a global model\ndef aggregate_models(client_models, testX):\n    client_preds = [model.predict(testX) for model in client_models]\n    avg_preds = np.mean(client_preds, axis=0)  # Averaging predicted probabilities\n    return np.argmax(avg_preds, axis=1)\n\n# Get predictions from federated model\npredictions = aggregate_models(client_models, testX)\n\n# Classification Report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Federated MobileNet Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    # Get class probabilities from each client model\n    probs = np.mean([model.predict(testX)[:, i] for model in client_models], axis=0)\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], probs)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T22:48:08.458759Z","iopub.execute_input":"2025-02-27T22:48:08.459147Z","iopub.status.idle":"2025-02-27T22:51:51.920513Z","shell.execute_reply.started":"2025-02-27T22:48:08.459119Z","shell.execute_reply":"2025-02-27T22:51:51.919657Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MobileNet without Data Augmentation - Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport seaborn as sns  # For heatmap visualization\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNet\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # MobileNet input size\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Normalize image data (scaling improves performance)\ndata = data.astype('float32') / 255.0\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Handle class imbalance by computing class weights\nclass_weights = compute_class_weight('balanced', classes=np.unique(trainY), y=trainY)\nclass_weights_dict = dict(zip(np.unique(trainY), class_weights))\n\n# Create the model function using MobileNet\ndef create_mobilenet_model():\n    # Load MobileNet as a base model without the top layers\n    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    base_model.trainable = False  # Freeze the pre-trained layers\n\n    # Use MobileNet with global average pooling and a dense classification layer\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),  # Global Average Pooling to handle small feature maps\n        layers.Dense(128, activation='relu'),\n        layers.Dense(len(le.classes_), activation='softmax')  # For multi-class classification\n    ])\n    \n    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Train local models (MobileNet backbone) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = create_mobilenet_model()\n    model.fit(client_data[i], client_labels[i], batch_size=32, epochs=10, \n              class_weight=class_weights_dict, verbose=1)\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Federated Aggregation: Combine client models into a global model\ndef aggregate_models(client_models, testX):\n    client_preds = [model.predict(testX) for model in client_models]\n    avg_preds = np.mean(client_preds, axis=0)  # Averaging predicted probabilities\n    return np.argmax(avg_preds, axis=1)\n\n# Get predictions from federated model\npredictions = aggregate_models(client_models, testX)\n\n# Classification Report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Federated MobileNet Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    # Get class probabilities from each client model\n    probs = np.mean([model.predict(testX)[:, i] for model in client_models], axis=0)\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], probs)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T22:52:25.430782Z","iopub.execute_input":"2025-02-27T22:52:25.431146Z","iopub.status.idle":"2025-02-27T22:54:04.791216Z","shell.execute_reply.started":"2025-02-27T22:52:25.431120Z","shell.execute_reply":"2025-02-27T22:54:04.790315Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ResNet50 with Data Augmentation - Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport seaborn as sns  # For heatmap visualization\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # ResNet50 input size\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Normalize image data (scaling improves performance)\ndata = data.astype('float32') / 255.0\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Handle class imbalance by computing class weights\nclass_weights = compute_class_weight('balanced', classes=np.unique(trainY), y=trainY)\nclass_weights_dict = dict(zip(np.unique(trainY), class_weights))\n\n# Create ImageDataGenerator for data augmentation\ntrain_datagen = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Create the model function using ResNet50\ndef create_resnet_model():\n    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    base_model.trainable = False  # Freeze the pre-trained layers\n\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(128, activation='relu'),\n        layers.Dense(len(le.classes_), activation='softmax')\n    ])\n    \n    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Train local models (ResNet50 backbone) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = create_resnet_model()\n    model.fit(train_datagen.flow(client_data[i], client_labels[i], batch_size=32), \n              epochs=10, \n              class_weight=class_weights_dict, \n              verbose=1)\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Federated Aggregation: Combine client models into a global model\ndef aggregate_models(client_models, testX):\n    client_preds = [model.predict(testX) for model in client_models]\n    avg_preds = np.mean(client_preds, axis=0)  # Averaging predicted probabilities\n    return np.argmax(avg_preds, axis=1)\n\n# Get predictions from federated model\npredictions = aggregate_models(client_models, testX)\n\n# Classification Report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Federated ResNet50 Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    probs = np.mean([model.predict(testX)[:, i] for model in client_models], axis=0)\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], probs)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T03:58:06.338509Z","iopub.execute_input":"2025-03-13T03:58:06.338838Z","iopub.status.idle":"2025-03-13T04:02:37.074556Z","shell.execute_reply.started":"2025-03-13T03:58:06.338804Z","shell.execute_reply":"2025-03-13T04:02:37.073690Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ResNet50 without Data Augmentation - Federated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport seaborn as sns  # For heatmap visualization\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # ResNet50 input size\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Normalize image data (scaling improves performance)\ndata = data.astype('float32') / 255.0\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Handle class imbalance by computing class weights\nclass_weights = compute_class_weight('balanced', classes=np.unique(trainY), y=trainY)\nclass_weights_dict = dict(zip(np.unique(trainY), class_weights))\n\ndef create_resnet50_model():\n    # Load ResNet50 as a base model without the top layers\n    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    base_model.trainable = False  # Freeze the pre-trained layers\n\n    # Use ResNet50 with global average pooling and a dense classification layer\n    model = models.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),  # Global Average Pooling to handle small feature maps\n        layers.Dense(128, activation='relu'),\n        layers.Dense(len(le.classes_), activation='softmax')  # For multi-class classification\n    ])\n    \n    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Train local models (ResNet50 backbone) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = create_resnet50_model()\n    model.fit(client_data[i], client_labels[i], batch_size=32, \n              epochs=10, class_weight=class_weights_dict, verbose=1)\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Federated Aggregation: Combine client models into a global model\ndef aggregate_models(client_models, testX):\n    client_preds = [model.predict(testX) for model in client_models]\n    avg_preds = np.mean(client_preds, axis=0)  # Averaging predicted probabilities\n    return np.argmax(avg_preds, axis=1)\n\n# Get predictions from federated model\npredictions = aggregate_models(client_models, testX)\n\n# Classification Report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Federated ResNet50 Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    # Get class probabilities from each client model\n    probs = np.mean([model.predict(testX)[:, i] for model in client_models], axis=0)\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], probs)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:36:44.072301Z","iopub.execute_input":"2025-03-21T02:36:44.072623Z","iopub.status.idle":"2025-03-21T02:40:01.558326Z","shell.execute_reply.started":"2025-03-21T02:36:44.072590Z","shell.execute_reply":"2025-03-21T02:40:01.557396Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# challenges While working with GoogleNet (Inception V3)","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import label_binarize\n\n# Set GPU memory growth before importing TensorFlow\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Optional: specify GPU if multiple GPUs are available\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        # Set memory growth for all GPUs\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n            # Optional: set memory limit if needed\n            # tf.config.set_logical_device_configuration(gpu, [tf.config.LogicalDeviceConfiguration(memory_limit=4096)])\n    except RuntimeError as e:\n        print(\"Error setting GPU memory growth:\", e)\n\n# Build the model function\ndef build_model(input_shape=(224, 224, 3), num_classes=10):\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n# Simulated data loading function (replace with actual data loading)\ndef load_data():\n    X_train = np.random.random((2310, 224, 224, 3))  # Random images (replace with real images)\n    y_train = np.random.randint(0, 10, 2310)  # Random labels (replace with real labels)\n    X_test = np.random.random((500, 224, 224, 3))  # Random test data\n    y_test = np.random.randint(0, 10, 500)  # Random test labels\n    return X_train, y_train, X_test, y_test\n\n# Ensure that the model uses GPU\nwith tf.device('/GPU:0'):  # Use the first GPU\n    X_train, y_train, X_test, y_test = load_data()\n\n    # Convert labels to one-hot encoding\n    y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n    y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n\n    # Initialize the model\n    model = build_model()\n\n    # Train the model\n    model.fit(X_train, y_train, epochs=5, batch_size=32)\n\n    # Evaluate the model on test data\n    test_loss, test_acc = model.evaluate(X_test, y_test)\n    print(f\"Test Loss: {test_loss}, Test Accuracy: {test_acc}\")\n\n    # Make predictions with the trained model\n    predictions = model.predict(X_test)\n\n    # Convert predictions to labels\n    y_pred = np.argmax(predictions, axis=1)\n    y_true = np.argmax(y_test, axis=1)\n\n    # Classification Report\n    print(\"Classification Report:\")\n    print(classification_report(y_true, y_pred))\n\n    # Accuracy\n    accuracy = accuracy_score(y_true, y_pred)\n    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n    # Confusion Matrix\n    conf_matrix = confusion_matrix(y_true, y_pred)\n    print(\"Confusion Matrix:\")\n    print(conf_matrix)\n\n    # ROC Curve & AUC Calculation\n    le = LabelEncoder()\n    y_bin = label_binarize(y_true, classes=range(10))  # Binarize the labels\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n\n    for i in range(10):\n        fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], predictions[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plot ROC Curve for each class\n    plt.figure(figsize=(10, 8))\n\n    for i in range(10):\n        plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n\n    # Plot diagonal reference line\n    plt.plot([0, 1], [0, 1], 'k--')\n\n    # Set plot limits and labels\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate (FPR)')\n    plt.ylabel('True Positive Rate (TPR)')\n    plt.title('ROC Curves for Each Class')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:53:29.441304Z","iopub.execute_input":"2025-03-21T02:53:29.441668Z","execution_failed":"2025-03-21T02:53:40.770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T02:51:48.786131Z","iopub.execute_input":"2025-03-21T02:51:48.786862Z","iopub.status.idle":"2025-03-21T02:51:48.803676Z","shell.execute_reply.started":"2025-03-21T02:51:48.786832Z","shell.execute_reply":"2025-03-21T02:51:48.802856Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inception V3(GoogleNet)","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, confusion_matrix\nimport seaborn as sns  # For heatmap visualization\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # InceptionV3 expects 224x224 input\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Normalize image data (scaling improves performance)\ndata = data.astype('float32') / 255.0\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Handle class imbalance by computing class weights\nclass_weights = compute_class_weight('balanced', classes=np.unique(trainY), y=trainY)\nclass_weights_dict = dict(zip(np.unique(trainY), class_weights))\n\n# Define the InceptionV3 model with fine-tuning\ndef create_inceptionv3_model(input_shape=(224, 224, 3), num_classes=10):\n    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n    x = base_model.output\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dense(1024, activation='relu')(x)\n    predictions = layers.Dense(num_classes, activation='softmax')(x)\n\n    model = models.Model(inputs=base_model.input, outputs=predictions)\n\n    # Freeze the layers of the base model (InceptionV3)\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Train local models (InceptionV3) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = create_inceptionv3_model()\n    model.fit(client_data[i], client_labels[i], epochs=10, batch_size=32, class_weight=class_weights_dict, verbose=1)\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Federated Aggregation: Combine client models into a global model\ndef aggregate_models(client_models, testX):\n    client_preds = [model.predict(testX) for model in client_models]\n    avg_preds = np.mean(client_preds, axis=0)  # Averaging predicted probabilities\n    return np.argmax(avg_preds, axis=1)\n\n# Get predictions from federated model\npredictions = aggregate_models(client_models, testX)\n\n# Classification Report\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Accuracy\naccuracy = accuracy_score(testY, predictions)\nprint(f\"Federated InceptionV3 Accuracy: {accuracy * 100:.2f}%\")\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    # Get class probabilities from each client model\n    probs = np.mean([model.predict(testX)[:, i] for model in client_models], axis=0)\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], probs)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T03:01:31.364316Z","iopub.execute_input":"2025-03-21T03:01:31.364738Z","iopub.status.idle":"2025-03-21T03:04:10.492401Z","shell.execute_reply.started":"2025-03-21T03:01:31.364709Z","shell.execute_reply":"2025-03-21T03:04:10.491400Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# DenseNet - Fedearated Learning","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, label_binarize\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\nimport seaborn as sns  # For heatmap visualization\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Function to get a list of all files in a directory and its subdirectories\ndef getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = []\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n    return allFiles\n\n# Fetch image paths from different subdirectories\nimagePaths_fp = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/test\")\nimagePaths_fl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/train\")\nimagePaths_dl = getListOfFiles(\"/kaggle/input/cotton-disease-dataset/Cotton Disease/val\")\n\n# Combine all image paths into a single list\nimagePaths = imagePaths_dl + imagePaths_fl + imagePaths_fp\n\ndata = []\nlabels = []\nc = 0  # To track progress\n\n# Load images and preprocess\nfor image in imagePaths:\n    label = os.path.split(os.path.split(image)[0])[1]\n    labels.append(label)\n\n    img = cv2.imread(image)\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # Resize to 224x224 for DenseNet\n    data.append(img)\n    c += 1\nprint(f\"Processed {c} images\")\n\n# Encode labels\ndata = np.array(data)\nlabels = np.array(labels)\n\nle = LabelEncoder()\nlabels = le.fit_transform(labels)\n\n# Normalize image data (scaling improves performance)\ndata = data.astype('float32') / 255.0\n\n# Split dataset into training and testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.30, random_state=42)\n\n# Number of clients for federated learning\nnum_clients = 4\n\n# Split data among clients\nclient_data = np.array_split(trainX, num_clients)\nclient_labels = np.array_split(trainY, num_clients)\n\n# Build DenseNet model function\ndef build_densenet_model():\n    input_layer = Input(shape=(224, 224, 3))  # DenseNet input shape\n    base_model = DenseNet121(weights='imagenet', include_top=False, input_tensor=input_layer)\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dense(512, activation='relu')(x)\n    x = Dense(len(np.unique(trainY)), activation='softmax')(x)  # Number of classes\n    model = Model(inputs=input_layer, outputs=x)\n\n    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n# Federated Learning: Train local models (DenseNet) on each client\nclient_models = []\nfor i in range(num_clients):\n    model = build_densenet_model()\n    model.fit(client_data[i], client_labels[i], epochs=10, validation_split=0.1, batch_size=32, verbose=1)\n    client_models.append(model)\n    print(f\"Client {i+1} trained.\")\n\n# Aggregation function: Averaging weights of client models\ndef aggregate_models(client_models):\n    # Initialize a list to store layer-wise aggregated weights\n    aggregated_weights = []\n    \n    # Get weights of the first client model\n    first_client_weights = client_models[0].get_weights()\n    \n    # Iterate through the layers of the models and average their weights\n    for layer_idx in range(len(first_client_weights)):\n        # Get weights for the current layer from all client models\n        layer_weights = np.array([model.get_weights()[layer_idx] for model in client_models])\n        \n        # Average the weights for this layer\n        avg_layer_weights = np.mean(layer_weights, axis=0)\n        \n        # Append the averaged weights for this layer to the aggregated weights\n        aggregated_weights.append(avg_layer_weights)\n    \n    # Create a new model with the same architecture (use your build function here)\n    global_model = build_densenet_model()\n    \n    # Set the averaged weights to the global model\n    global_model.set_weights(aggregated_weights)\n    \n    return global_model\n\n# Aggregate the weights from the client models into a global model\nglobal_model = aggregate_models(client_models)\n\n# Evaluate the global model on the test set\ntest_loss, test_acc = global_model.evaluate(testX, testY)\nprint(f\"Accuracy of DenseNet model is: {test_acc * 100:.2f}%\")\n\n# Classification Report\npredictions = np.argmax(global_model.predict(testX), axis=1)\nprint(classification_report(testY, predictions, target_names=le.classes_))\n\n# Confusion Matrix\nconf_matrix = confusion_matrix(testY, predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# ROC Curve & AUC Calculation\ny_bin = label_binarize(testY, classes=list(range(len(le.classes_))))\n\n# Compute ROC for each class\ntpr = dict()\nfpr = dict()\nroc_auc = dict()\n\nfor i in range(len(le.classes_)):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], global_model.predict(testX)[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC Curve for each class\nplt.figure(figsize=(6, 6))\n\nfor i in range(len(le.classes_)):\n    plt.plot(fpr[i], tpr[i], label=f'Class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n\n# Plot diagonal reference line\nplt.plot([0, 1], [0, 1], 'k--')\n\n# Set plot limits and labels\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Each Class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T02:54:21.425456Z","iopub.execute_input":"2025-04-18T02:54:21.425785Z","iopub.status.idle":"2025-04-18T03:09:40.791215Z","shell.execute_reply.started":"2025-04-18T02:54:21.425755Z","shell.execute_reply":"2025-04-18T03:09:40.790366Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}